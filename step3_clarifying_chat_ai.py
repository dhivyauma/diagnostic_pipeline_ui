# step3_clarifying_chat_ai.py
import streamlit as st
from typing import Dict, Any, List, Optional, Literal
from datetime import datetime
import json
from pathlib import Path
from pydantic import BaseModel, Field
import os

from dotenv import load_dotenv
from pydantic_ai import Agent


class DiagnosticContext(BaseModel):
    """Context for the diagnostic pipeline"""
    model_type: str = Field(..., description="Model type (PD, LGD, EAD)")
    portfolio: str = Field(..., description="Portfolio type (Retail, Commercial, Wholesale)")
    purpose: str = Field(..., description="Purpose (IFRS9, AIRB, Adjudication)")
    active_requirements: Dict[str, Any] = Field(..., description="Active requirements from Step 2")
    collected_data: Dict[str, Any] = Field(default_factory=dict, description="Collected user responses so far")


class FieldStatus(BaseModel):
    """Status of a field in the clarifying chat"""
    field_name: str
    status: str = Field(..., description="pending, provided, clarified")
    value: Optional[str] = None
    timestamp: Optional[datetime] = None


class ClarifyingQuestion(BaseModel):
    """A clarifying question generated by the AI agent"""
    field_name: str
    question: str
    context: str
    example: Optional[str] = None
    is_mandatory: bool
    field_type: str


class UserResponse(BaseModel):
    """User response to a clarifying question"""
    field_name: str
    response: str
    timestamp: datetime = Field(default_factory=datetime.now)


class ChatSession(BaseModel):
    """Complete chat session state"""
    context: DiagnosticContext
    collected_data: Dict[str, str] = Field(default_factory=dict)
    field_status: Dict[str, FieldStatus] = Field(default_factory=dict)
    chat_history: List[Dict[str, Any]] = Field(default_factory=list)
    current_question: Optional[ClarifyingQuestion] = None
    question_cache: Dict[str, ClarifyingQuestion] = Field(default_factory=dict)
    question_cache_llm: Dict[str, bool] = Field(default_factory=dict)


class _LLMDeps(BaseModel):
    model_type: str
    portfolio: str
    purpose: str
    requirements_context: Dict[str, Any]
    active_requirements: Dict[str, Any]
    collected_data: Dict[str, Any]
    chat_history: List[Dict[str, Any]]
    field_name: str
    field_config: Dict[str, Any]


class _LLMQuestionOutput(BaseModel):
    question: str
    context: str
    example: Optional[str] = None
    field_type: Literal['text', 'numeric', 'boolean']


class _ChatDeps(BaseModel):
    model_type: str
    portfolio: str
    purpose: str
    requirements_context: Dict[str, Any]
    active_requirements: Dict[str, Any]
    collected_data: Dict[str, Any]
    chat_history: List[Dict[str, Any]]
    user_message: str
    expected_field_name: str
    expected_field_config: Dict[str, Any]


class _FieldUpdate(BaseModel):
    field_name: str
    value: str


class _ChatOutput(BaseModel):
    assistant_message: str
    updates: List[_FieldUpdate] = Field(default_factory=list)
    followup_question: Optional[str] = None


def _generate_question_text(field_name: str) -> str:
    return f"What is your {field_name.replace('_', ' ')}?"


class ClarifyingChatAIAgent:
    """Step 3 - Clarifying Chat AI Agent
    
    Uses PydanticAI to ask clarifying questions based on the
    diagnostic context and requirements from Step 2.
    """
    
    def __init__(self):
        self.session: Optional[ChatSession] = None
        self.agent: Optional[Agent] = None
        self.chat_agent: Optional[Agent] = None
        self.last_ai_error: Optional[str] = None
        self.last_question_ai_error: Optional[str] = None
        self.last_chat_ai_error: Optional[str] = None
        self.last_question_rejection: Optional[str] = None

        self.model_name: Optional[str] = None
        self.requirements_context: Dict[str, Any] = {}

        load_dotenv()
        self._load_requirements_context()
        self._init_llm()

    def _load_requirements_context(self) -> None:
        try:
            base_dir = Path(__file__).resolve().parent
            ctx_path = base_dir / 'requirements_context.json'
            if ctx_path.exists():
                with open(ctx_path, 'r', encoding='utf-8') as f:
                    self.requirements_context = json.load(f)
        except Exception:
            self.requirements_context = {}

    def _init_llm(self) -> None:
        raw_key = (
            os.getenv('OPENROUTER_API_KEY')
            or os.getenv('OPENAI_API_KEY')
            or os.getenv('openai_API_KEY')
        )
        if isinstance(raw_key, str):
            raw_key = raw_key.strip()

        if raw_key and raw_key.startswith('sk-or-') and not os.getenv('OPENROUTER_API_KEY'):
            os.environ['OPENROUTER_API_KEY'] = raw_key

        if not os.getenv('OPENAI_API_KEY') and os.getenv('openai_API_KEY'):
            os.environ['OPENAI_API_KEY'] = os.getenv('openai_API_KEY', '').strip()

        model_name_env = (os.getenv('CLARIFYING_CHAT_MODEL') or os.getenv('PYDANTIC_AI_MODEL') or '').strip()
        model_name = model_name_env or ''

        known_providers = {
            'openai',
            'openrouter',
            'anthropic',
            'gemini',
            'ollama',
            'mistral',
            'deepseek',
            'azure',
            'bedrock',
        }

        if model_name:
            prefix = model_name.split(':', 1)[0].strip().lower() if ':' in model_name else ''
            has_known_prefix = bool(prefix) and prefix in known_providers

            if not has_known_prefix:
                if os.getenv('OPENROUTER_API_KEY'):
                    model_name = f'openrouter:{model_name}'
                elif os.getenv('OPENAI_API_KEY'):
                    model_name = f'openai:{model_name}'
        else:
            if os.getenv('OPENROUTER_API_KEY'):
                model_name = 'openrouter:openai/gpt-oss-20b:free'
            else:
                model_name = 'openai:gpt-4o-mini'

        self.model_name = model_name

        try:
            self.agent = Agent(
                model_name,
                deps_type=_LLMDeps,
                output_type=_LLMQuestionOutput,
                system_prompt=(
                    'You are a requirements-clarification assistant for a credit risk diagnostic pipeline. '
                    'Generate one clear question for the specified field, using the field config (description/example) '
                    'and the diagnostic header (model_type, portfolio, purpose). '
                    'Return JSON matching the output schema.'
                ),
            )
        except Exception as e:
            self.last_ai_error = str(e)
            self.last_question_ai_error = self.last_ai_error
            self.agent = None

        try:
            self.chat_agent = Agent(
                model_name,
                deps_type=_ChatDeps,
                output_type=_ChatOutput,
                system_prompt=(
                    'You are a chat assistant collecting missing configuration fields for a credit risk diagnostic pipeline. '
                    'You will be given diagnostic header (model_type, portfolio, purpose), requirements context, active requirements, '
                    'collected data so far, chat history, and the user\'s latest message. '
                    'You will also be told expected_field_name (the next missing field) and its config. '
                    'Extract field values from the user message and return them as updates. '
                    'Prioritize expected_field_name. Only return updates for fields that exist in active_requirements. '
                    'If no usable value for expected_field_name is present, set updates=[] and ask exactly one specific follow-up question '
                    'for expected_field_name (use its description/example). '
                    'Never ask the user to provide diagnostic header or requirements context. '
                    'Return JSON matching the output schema.'
                ),
            )
        except Exception as e:
            self.last_ai_error = str(e)
            self.last_chat_ai_error = self.last_ai_error
            self.chat_agent = None

    def _credits_exhausted(self, err: Optional[str]) -> bool:
        if not err:
            return False
        e = str(err)
        return ('status_code: 402' in e) or ('Insufficient credits' in e)

    def _provider_key_ready(self) -> bool:
        model_name = self.model_name or ''
        provider = model_name.split(':', 1)[0].strip().lower() if ':' in model_name else ''
        if provider == 'openrouter':
            return bool(os.getenv('OPENROUTER_API_KEY'))
        return bool(os.getenv('OPENAI_API_KEY') or os.getenv('openai_API_KEY'))

    def _question_llm_ready(self) -> bool:
        if self.agent is None:
            return False
        if self._credits_exhausted(self.last_question_ai_error):
            return False
        return self._provider_key_ready()

    def _chat_llm_ready(self) -> bool:
        if self.chat_agent is None:
            return False
        if self._credits_exhausted(self.last_chat_ai_error):
            return False
        return self._provider_key_ready()

    def _llm_ready(self) -> bool:
        return self._question_llm_ready() or self._chat_llm_ready()

    def get_next_pending_question(self) -> Optional[ClarifyingQuestion]:
        if not self.session:
            raise ValueError("Session not initialized")

        next_field = self._get_next_field_to_ask()
        if next_field == "ALL_COMPLETE":
            return None
        return self._generate_question_for_field(next_field)

    def handle_user_message(self, user_message: str) -> Dict[str, Any]:
        if not self.session:
            return {'success': False, 'message': 'Session not initialized'}

        cleaned_message = str(user_message or '').strip()
        if not cleaned_message:
            return {'success': False, 'message': 'Message cannot be empty'}

        self.session.chat_history.append({
            'role': 'user',
            'field_name': None,
            'content': cleaned_message,
            'timestamp': datetime.now().isoformat(),
        })

        expected_field = self._get_next_field_to_ask()
        expected_field_config = (
            self.session.context.active_requirements.get(expected_field, {})
            if expected_field != 'ALL_COMPLETE'
            else {}
        )

        assistant_message = ''
        followup_question: Optional[str] = None
        updates: List[Dict[str, Any]] = []
        applied: List[Dict[str, Any]] = []
        rejected: List[Dict[str, Any]] = []

        can_call_llm = self._chat_llm_ready()
        if can_call_llm and expected_field != 'ALL_COMPLETE':
            deps = _ChatDeps(
                model_type=self.session.context.model_type,
                portfolio=self.session.context.portfolio,
                purpose=self.session.context.purpose,
                requirements_context=self.requirements_context,
                active_requirements=self.session.context.active_requirements,
                collected_data=self.session.context.collected_data,
                chat_history=self.session.chat_history,
                user_message=cleaned_message,
                expected_field_name=expected_field,
                expected_field_config=expected_field_config,
            )

            allowed_fields = sorted(list(self.session.context.active_requirements.keys()))
            expected_desc = str(expected_field_config.get('description', '') or '').strip()
            expected_example = str(expected_field_config.get('example', '') or '').strip()

            prompt = (
                'Extract configuration field updates from the user message.\n'
                'Return JSON matching the output schema.\n\n'
                f"Diagnostic header: model_type={deps.model_type}, portfolio={deps.portfolio}, purpose={deps.purpose}\n\n"
                f"Allowed fields: {allowed_fields}\n\n"
                f"Expected field to collect next: {deps.expected_field_name}\n"
                f"Expected field description: {expected_desc}\n"
                f"Expected field example: {expected_example}\n\n"
                f"User message: {deps.user_message}"
            )

            output = None
            last_exc: Optional[Exception] = None
            for attempt in range(2):
                try:
                    result = self.chat_agent.run_sync(prompt, deps=deps)
                    output = result.output
                    last_exc = None
                    break
                except Exception as e:
                    self.last_ai_error = str(e)
                    self.last_chat_ai_error = self.last_ai_error
                    last_exc = e
                    if 'Received empty model response' in self.last_ai_error and attempt == 0:
                        continue
                    break

            if last_exc is None and isinstance(output, _ChatOutput):
                assistant_message = str(output.assistant_message or '').strip()
                followup_question = str(output.followup_question).strip() if output.followup_question else None
                updates = [u.model_dump() for u in (output.updates or [])]

        def _asks_for_internal_context(text: Optional[str]) -> bool:
            if not text:
                return False
            t = str(text).lower()
            return (
                'provide the diagnostic header' in t
                or 'diagnostic header' in t
                or 'requirements context' in t
                or 'active requirements' in t
                or 'expected field name' in t
                or 'expected field' in t
            )

        if _asks_for_internal_context(assistant_message):
            assistant_message = ''
        if _asks_for_internal_context(followup_question):
            followup_question = None

        for u in updates:
            field_name = str(u.get('field_name', '')).strip()
            value = str(u.get('value', '')).strip()
            if not field_name or not value:
                rejected.append({'field_name': field_name, 'value': value, 'reason': 'missing_field_or_value'})
                continue
            if field_name not in self.session.context.active_requirements:
                rejected.append({'field_name': field_name, 'value': value, 'reason': 'unknown_field'})
                continue

            pr = self.process_user_response(field_name, value, record_chat=False)
            if pr.get('success'):
                applied.append({'field_name': field_name, 'value': pr.get('value')})
            else:
                rejected.append({'field_name': field_name, 'value': value, 'reason': pr.get('message')})

        if expected_field != 'ALL_COMPLETE' and not applied:
            pr = self.process_user_response(expected_field, cleaned_message, record_chat=False)
            if pr.get('success'):
                applied.append({'field_name': expected_field, 'value': pr.get('value')})
            else:
                rejected.append({'field_name': expected_field, 'value': cleaned_message, 'reason': pr.get('message')})

        if applied:
            pass

        if applied:
            assistant_message = ''
            followup_question = None

        assistant_parts: List[str] = []
        if assistant_message:
            assistant_parts.append(assistant_message)
        if followup_question and expected_field != 'ALL_COMPLETE':
            assistant_parts.append(followup_question)

        assistant_text = '\n\n'.join([p for p in assistant_parts if str(p).strip()])
        if assistant_text:
            self.session.chat_history.append({
                'role': 'assistant',
                'field_name': expected_field if expected_field != 'ALL_COMPLETE' else None,
                'content': assistant_text,
                'timestamp': datetime.now().isoformat(),
            })

        return {
            'success': True,
            'assistant_message': assistant_text,
            'applied_updates': applied,
            'rejected_updates': rejected,
            'completion_status': self.get_completion_status(),
            'current_json': self.get_current_json(),
        }
    
    def initialize_session(self, model_type: str, portfolio: str, purpose: str, 
                          active_requirements: Dict[str, Any]) -> None:
        """Initialize a new chat session with the diagnostic context"""
        # Create diagnostic context
        context = DiagnosticContext(
            model_type=model_type,
            portfolio=portfolio,
            purpose=purpose,
            active_requirements=active_requirements
        )
        
        # Initialize session
        self.session = ChatSession(context=context)
        
        # Initialize field status for all requirements
        for field_name in active_requirements.keys():
            self.session.field_status[field_name] = FieldStatus(
                field_name=field_name,
                status="pending"
            )
    
    async def generate_next_question(self) -> Optional[ClarifyingQuestion]:
        """Generate the next clarifying question."""
        if not self.session:
            raise ValueError("Session not initialized")
        
        # Check if we're done
        next_field = self._get_next_field_to_ask()
        if next_field == "ALL_COMPLETE":
            return None

        question = self._generate_question_for_field(next_field)
        self.session.current_question = question
        return question

    def _generate_question_for_field(self, field_name: str) -> ClarifyingQuestion:
        if not self.session:
            raise ValueError('Session not initialized')

        cached = self.session.question_cache.get(field_name)
        if cached is not None:
            cached_is_llm = bool(self.session.question_cache_llm.get(field_name, False))
            if cached_is_llm or not self._question_llm_ready():
                return cached

        field_config = self.session.context.active_requirements.get(field_name, {})
        default_question_text = _generate_question_text(field_name)
        question_text = default_question_text
        context_text = str(field_config.get('description', '') or '')
        example_text = field_config.get('example')
        field_type = self._determine_field_type(field_config)

        def _looks_like_prompt_metadata(text: str) -> bool:
            t = str(text or '').lower()
            return (
                'diagnostic header' in t
                or 'field config' in t
                or 'active requirements' in t
                or 'collected data' in t
                or 'return json' in t
            )

        def _sanitize_llm_question(text: str) -> str:
            raw = str(text or '').strip()
            if not raw:
                return ''

            lines = [ln.strip() for ln in raw.splitlines() if ln.strip()]
            cleaned: List[str] = []
            for ln in lines:
                low = ln.lower()
                if low.startswith('context:') or low.startswith('example:'):
                    continue
                if _looks_like_prompt_metadata(low):
                    continue
                cleaned.append(ln)

            if not cleaned:
                return ''

            # Prefer a single interrogative line if present
            for ln in cleaned:
                if ln.endswith('?'):
                    return ln

            # Otherwise take the first line and add a question mark if it reads like a question
            first = cleaned[0]
            if first and not first.endswith('?'):
                first = first + '?'
            return first

        used_llm = False
        self.last_question_rejection = None
        if self._question_llm_ready():
            deps = _LLMDeps(
                model_type=self.session.context.model_type,
                portfolio=self.session.context.portfolio,
                purpose=self.session.context.purpose,
                requirements_context=self.requirements_context,
                active_requirements=self.session.context.active_requirements,
                collected_data=self.session.context.collected_data,
                chat_history=self.session.chat_history,
                field_name=field_name,
                field_config=field_config,
            )

            prompt = (
                'Generate the next clarifying question for the specified field.\n\n'
                f'Diagnostic header:\n{json.dumps({"model_type": deps.model_type, "portfolio": deps.portfolio, "purpose": deps.purpose}, indent=2)}\n\n'
                f'Field to generate question for: {deps.field_name}\n'
                f'Field config:\n{json.dumps(deps.field_config, indent=2)}\n\n'
                f'Collected data so far:\n{json.dumps(deps.collected_data, indent=2)}\n\n'
            )

            last_exc: Optional[Exception] = None
            output = None
            for attempt in range(2):
                try:
                    result = self.agent.run_sync(prompt, deps=deps)
                    output = result.output
                    last_exc = None
                    break
                except Exception as e:
                    last_exc = e
                    self.last_ai_error = str(e)
                    self.last_question_ai_error = self.last_ai_error
                    if 'Received empty model response' in self.last_ai_error and attempt == 0:
                        continue
                    break

            if last_exc is None and isinstance(output, _LLMQuestionOutput):
                raw_q = str(output.question or '')
                sanitized_q = _sanitize_llm_question(raw_q)
                if sanitized_q and sanitized_q.strip() and not _looks_like_prompt_metadata(sanitized_q):
                    question_text = sanitized_q.strip()
                    used_llm = True
                field_type = str(output.field_type)

                if not used_llm:
                    preview = raw_q.strip().replace('\n', ' ')[:160]
                    self.last_question_rejection = f'LLM question rejected (unusable/metadata). Raw preview: {preview}'
            elif last_exc is not None:
                self.last_question_rejection = f'LLM question failed: {str(last_exc)[:160]}'

        question = ClarifyingQuestion(
            field_name=field_name,
            question=question_text,
            context=context_text,
            example=example_text,
            is_mandatory=bool(field_config.get('mandatory', False)),
            field_type=field_type,
        )
        self.session.question_cache[field_name] = question
        self.session.question_cache_llm[field_name] = used_llm
        return question

    def _get_next_field_to_ask(self) -> str:
        """Get the next field to ask about"""
        if not self.session:
            return "ALL_COMPLETE"
        
        collected = set(self.session.collected_data.keys())
        
        # Priority: mandatory fields first
        for field_name, field_config in self.session.context.active_requirements.items():
            if field_config.get('mandatory', False) and field_name not in collected:
                return field_name
        
        # Then optional fields
        for field_name, field_config in self.session.context.active_requirements.items():
            if not field_config.get('mandatory', False) and field_name not in collected:
                return field_name
        
        return "ALL_COMPLETE"

    def _determine_field_type(self, field_config: Dict[str, Any]) -> str:
        """Determine the appropriate input type for the field"""
        example = field_config.get('example', '').lower()
        
        # Check for boolean indicators
        if any(indicator in example for indicator in ['yes/no', 'true/false', 'on/off']):
            return 'boolean'
        
        # Check for numeric indicators
        if any(indicator in example for indicator in ['years', 'months', '%', 'rate']):
            return 'numeric'
        
        return 'text'
    
    def process_user_response(self, field_name: str, user_input: str, record_chat: bool = True) -> Dict[str, Any]:
        """Process and validate user response"""
        if not self.session:
            return {'success': False, 'message': 'Session not initialized'}
        
        try:
            # Validate input
            if not user_input or not user_input.strip():
                return {
                    'success': False,
                    'message': 'Response cannot be empty',
                    'field_name': field_name
                }
            
            # Store the response
            cleaned_input = user_input.strip()
            self.session.collected_data[field_name] = cleaned_input
            self.session.context.collected_data[field_name] = cleaned_input
            
            # Update field status
            self.session.field_status[field_name].status = "provided"
            self.session.field_status[field_name].value = cleaned_input
            self.session.field_status[field_name].timestamp = datetime.now()
            
            # Add to chat history
            if record_chat:
                self.session.chat_history.append({
                    'role': 'user',
                    'field_name': field_name,
                    'content': cleaned_input,
                    'timestamp': datetime.now().isoformat()
                })
            
            return {
                'success': True,
                'message': f"{field_name.replace('_', ' ').title()} recorded successfully.",
                'field_name': field_name,
                'value': cleaned_input
            }
            
        except Exception as e:
            return {
                'success': False,
                'message': f"Error processing response: {str(e)}",
                'field_name': field_name
            }
    
    def get_completion_status(self) -> Dict[str, Any]:
        """Get the current completion status of all fields"""
        if not self.session:
            return {'error': 'Session not initialized'}
        
        mandatory_fields = [
            field for field, config in self.session.context.active_requirements.items()
            if config.get('mandatory', False)
        ]
        
        optional_fields = [
            field for field, config in self.session.context.active_requirements.items()
            if not config.get('mandatory', False)
        ]
        
        mandatory_completed = sum(
            1 for field in mandatory_fields
            if self.session.field_status.get(field, FieldStatus(field_name=field, status="pending")).status == "provided"
        )
        
        optional_completed = sum(
            1 for field in optional_fields
            if self.session.field_status.get(field, FieldStatus(field_name=field, status="pending")).status == "provided"
        )
        
        return {
            'mandatory_total': len(mandatory_fields),
            'mandatory_completed': mandatory_completed,
            'optional_total': len(optional_fields),
            'optional_completed': optional_completed,
            'all_mandatory_complete': mandatory_completed == len(mandatory_fields),
            'all_complete': (mandatory_completed == len(mandatory_fields) and
                           optional_completed == len(optional_fields))
        }
    
    def get_collected_data(self) -> Dict[str, Any]:
        """Get all collected data in the format expected for Step 4"""
        if not self.session:
            return {'error': 'Session not initialized'}
        
        return {
            'header': {
                'model_type': self.session.context.model_type,
                'portfolio': self.session.context.portfolio,
                'purpose': self.session.context.purpose
            },
            'user_specs': self.session.collected_data.copy(),
            'completion_status': self.get_completion_status(),
            'chat_history': self.session.chat_history.copy(),
            'timestamp': datetime.now().isoformat()
        }
    
    def get_current_json(self) -> Dict[str, Any]:
        """Get the current JSON state in real-time as user fills the form"""
        if not self.session:
            return {'error': 'Session not initialized'}
        
        current_json = {
            'header': {
                'model_type': self.session.context.model_type,
                'portfolio': self.session.context.portfolio,
                'purpose': self.session.context.purpose
            },
            'user_specs': self.session.collected_data.copy(),
            'metadata': {
                'last_updated': datetime.now().isoformat(),
                'completion_status': self.get_completion_status(),
                'total_fields': len(self.session.context.active_requirements),
                'completed_fields': len(self.session.collected_data)
            }
        }
        
        return current_json
    
    def save_current_json(self, filename: Optional[str] = None) -> str:
        """Save the current JSON state to file"""
        if not self.session:
            raise ValueError("Session not initialized")
        
        current_json = self.get_current_json()
        
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            header = current_json["header"]
            filename = f"current_diagnostic_{header['model_type']}_{header['portfolio']}_{header['purpose']}_{timestamp}.json"

        from pathlib import Path as _Path

        base_dir = _Path(__file__).resolve().parent
        output_dir = base_dir / "outputs"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        filepath = output_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(current_json, f, indent=2)
        
        return str(filepath)
    
    def can_proceed_to_step4(self) -> bool:
        """Check if all mandatory fields are complete"""
        if not self.session:
            return False
        
        status = self.get_completion_status()
        return status.get('all_mandatory_complete', False)
    
    def get_field_summary(self) -> List[Dict[str, Any]]:
        """Get a summary of all fields and their status"""
        if not self.session:
            return []
        
        summary = []
        for field_name, field_config in self.session.context.active_requirements.items():
            field_status = self.session.field_status.get(field_name, FieldStatus(field_name=field_name, status="pending"))
            
            summary.append({
                'field_name': field_name,
                'display_name': field_name.replace('_', ' ').title(),
                'mandatory': field_config.get('mandatory', False),
                'status': field_status.status,
                'value': field_status.value or '',
                'description': field_config.get('description', ''),
                'example': field_config.get('example', '')
            })
        
        return summary
    
    def reset_session(self) -> None:
        """Reset the current session"""
        self.session = None
